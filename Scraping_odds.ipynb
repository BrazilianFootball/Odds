{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup_from_url(url):\n",
    "    response = requests.get(url, headers = HEADER)\n",
    "    return BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "def get_soup_from_string(html):\n",
    "    html = f'<html><body>{html}</body></html>'\n",
    "    return BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "def catch_tables(soup, replace_str):\n",
    "    tblehead_divs = soup.find_all('div', class_='tblehead')\n",
    "    tables = dict()\n",
    "    for div in tblehead_divs:\n",
    "        header = div.get_text(strip=True).replace(f'{replace_str}', '')\n",
    "        table = div.find_next('table')\n",
    "        if table: tables[header] = table\n",
    "    \n",
    "    return tables\n",
    "\n",
    "def catch_game_url(tables):\n",
    "    for header in tables:\n",
    "        new_soup = get_soup_from_string(tables[header])\n",
    "        internal_tables = new_soup.find_all('table', class_='tble')\n",
    "        tables[header] = dict()\n",
    "        count = 0\n",
    "        for table in internal_tables:\n",
    "            links = table.find_all('a', href=True)\n",
    "            for link in links:\n",
    "                href = link['href']\n",
    "                text = link.get_text(strip=True)\n",
    "                if text in tables[header]: text += ' (playoff)'\n",
    "                tables[header][text] = f'https://checkbestodds.com{href}'\n",
    "                count += 1\n",
    "        \n",
    "        if count != len(tables[header]):\n",
    "            print(f'{header} with inconsistency. Collected {count} games, but saved only {len(tables[header])}.')\n",
    "\n",
    "    return tables\n",
    "\n",
    "def catch_odds_table(game_soup):\n",
    "    game_tables = dict()\n",
    "    tblehead_divs = game_soup.find_all('div', class_='tblehead')\n",
    "    for div in tblehead_divs:\n",
    "        header = div.get_text(strip=True)\n",
    "        table = div.find_next('table')\n",
    "        if table: game_tables[header] = table\n",
    "\n",
    "    return game_tables\n",
    "\n",
    "def catch_odds(game_tables):\n",
    "    for header in game_tables:\n",
    "        new_soup = get_soup_from_string(game_tables[header])\n",
    "        internal_tables = new_soup.find_all('table', class_='tble sort6')\n",
    "        game_tables[header] = dict()\n",
    "        for table in internal_tables:\n",
    "            rows = table.find_all('tr')[1:]\n",
    "            for row in rows:\n",
    "                columns = row.find_all('td')\n",
    "                if len(columns) >= 3:\n",
    "                    bookmaker = columns[0].get_text(strip=True)\n",
    "                    if bookmaker == 'Best odds': continue\n",
    "                    home_team_odd = columns[1].find('span', class_='toSort noDsp').get_text(strip=True)\n",
    "                    draw_odd = columns[2].find('span', class_='toSort noDsp').get_text(strip=True)\n",
    "                    away_team_odd = columns[3].find('span', class_='toSort noDsp').get_text(strip=True)\n",
    "                    game_tables[header][bookmaker] = [home_team_odd, draw_odd, away_team_odd]\n",
    "\n",
    "    return game_tables\n",
    "\n",
    "def save_odds(odds, year):\n",
    "    df = pd.DataFrame(columns = ['Year', 'Competition', 'Game', 'Odd group', 'House', 'Home', 'Draw', 'Away'])\n",
    "    for competition in odds:\n",
    "        for game in odds[competition]:\n",
    "            for odd_group in odds[competition][game]:\n",
    "                for house in odds[competition][game][odd_group]:\n",
    "                    df.loc[len(df)] = [year, competition, game, odd_group, house] + odds[competition][game][odd_group][house]\n",
    "\n",
    "    df.to_csv(f'odds/{year}.csv', index = False)\n",
    "\n",
    "def extract_odds(year):\n",
    "    odds = dict()\n",
    "    url = f'https://checkbestodds.com/football-odds/archive-brazil/{year}'\n",
    "    soup = get_soup_from_url(url)\n",
    "    odds = catch_tables(soup, 'Best odds')\n",
    "    odds = catch_game_url(odds)\n",
    "    for competition in odds:\n",
    "        for game in tqdm(odds[competition]):\n",
    "            game_soup = get_soup_from_url(odds[competition][game])\n",
    "            odds[competition][game] = catch_odds_table(game_soup)\n",
    "            odds[competition][game] = catch_odds(odds[competition][game])\n",
    "    \n",
    "    save_odds(odds, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2009, 2025):\n",
    "    if f'odds/{year}.csv' in glob('odds/*.csv'): continue\n",
    "    print(year)\n",
    "    extract_odds(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68a818ea200cf26246555ed215b2805781440e4bd9c1dd7c5d891140b3a1e7c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
